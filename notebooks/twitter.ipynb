{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Twitter data using Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Tweepy to analyze Twitter data with Python\n",
    "import tweepy\n",
    "from string import punctuation\n",
    "## Import the Natural Language Toolkit\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Twitter Data using the Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect Jupyter to your Crowdmark API key.\n",
    "# Please place your Crowdmark API key somewhere and link to it by adjusting the route below.\n",
    "# The API key allows the computer hosting your Jupyter notebook to programmatically access data from Crowdmark.\n",
    "with open(\"/home/jcollian/.twitter-keys\", 'r') as f:\n",
    "    Twitter_Keys = f.read()\n",
    "# apiKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Twitter_Keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hack: Define a dictionary with `keys = {...}` using the content from Twitter_Keys. The dictionary will populate your Twitter keys below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James Colliander\n"
     ]
    }
   ],
   "source": [
    "# == OAuth Authentication ==\n",
    "#\n",
    "# This mode of authentication is the new preferred way\n",
    "# of authenticating with Twitter.\n",
    "# Source: https://github.com/tweepy/tweepy/blob/master/examples/oauth.py\n",
    "\n",
    "# The consumer keys can be found on your application's Details\n",
    "# page located at https://dev.twitter.com/apps (under \"OAuth settings\")\n",
    "\n",
    "consumer_key=keys[consumer_key]\n",
    "consumer_secret= keys[consumer_secret]\n",
    "\n",
    "# The access tokens can be found on your applications's Details\n",
    "# page located at https://dev.twitter.com/apps (located\n",
    "# under \"Your access token\")\n",
    "access_token=keys[access_token]\n",
    "access_token_secret=keys[access_token_secret]\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.secure = True\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# If the authentication was successful, you should\n",
    "# see the name of the account print out\n",
    "print(api.me().name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the Twitter Account to Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "screenName = 'pimsmath'\n",
    "tweetsPerRetrieval = 50\n",
    "\n",
    "# return list of Status object instances\n",
    "data = api.user_timeline(\n",
    "    screen_name=screenName,\n",
    "    count=tweetsPerRetrieval,\n",
    "    tweet_mode='extended', # avoid truncation\n",
    "    include_rts=True # include retweets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 1581 tweets!\n"
     ]
    }
   ],
   "source": [
    "# Collect recent tweets\n",
    "tweets = [] + data # extend first tweets\n",
    "lastIndex = tweets[-1].id - 1 # get last tweet index\n",
    "\n",
    "# recover tweets\n",
    "while len(data) > 0:\n",
    "    data = api.user_timeline(\n",
    "        screen_name=screenName,\n",
    "        count=tweetsPerRetrieval,\n",
    "        max_id=lastIndex, # prevent duplicates\n",
    "        tweet_mode='extended',\n",
    "        include_rts=True,\n",
    "    )\n",
    "    tweets += data\n",
    "    lastIndex = tweets[-1].id - 1\n",
    "print('Retrieved %d tweets!' % len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colliand', 'UBCStatistics', 'UBC', 'UBCDSI', 'uvic']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isolate mentions, get names\n",
    "mentions = [m['screen_name']\n",
    "                for t in tweets\n",
    "                    for m in t.entities['user_mentions']]\n",
    "mentions[:5] # slice first five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://pbs.twimg.com/media/DYvkYukWAAAnHzS.jpg',\n",
       " 'http://pbs.twimg.com/media/DYv6eUVX0AAzNv2.jpg',\n",
       " 'http://pbs.twimg.com/media/DYa1hn2VMAAx855.jpg',\n",
       " 'http://pbs.twimg.com/media/DX4JltvWsAMQzNN.jpg',\n",
       " 'http://pbs.twimg.com/media/DXx8nhZVAAA7aDP.jpg',\n",
       " 'http://pbs.twimg.com/media/DXjpUuMUMAALaox.jpg',\n",
       " 'http://pbs.twimg.com/media/DXD5dcEVoAAe0Uv.jpg',\n",
       " 'http://pbs.twimg.com/media/DWaa1OEVoAAeJ1j.jpg',\n",
       " 'http://pbs.twimg.com/media/DWa3Q-zUMAAF-tF.jpg',\n",
       " 'http://pbs.twimg.com/media/DWGNfuNX4AA4C6Z.jpg']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isolate media, get each URL\n",
    "remedia = [m['media_url']\n",
    "               for t in tweets\n",
    "                   if hasattr(t, 'retweeted_status')\n",
    "                   and 'media' in t.retweeted_status.entities\n",
    "                       for m in t.retweeted_status.entities['media']]\n",
    "\n",
    "media = remedia + [m['media_url']\n",
    "                       for t in tweets\n",
    "                           if 'media' in t.entities \n",
    "                               for m in t.entities['media']]\n",
    "media[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A poster session showcasing work in @UBCStatistics will take place @UBC next Tuesday. https://t.co/I34ZfHY1Ie FYI @UBCDSI @ubcprez @pimsmath @ubcmath',\n",
       " 'Today at @uvic, a PIMS-UVic Distinguished Lecture from Leslie Hogben of @IowaStateU &amp; @AIMathematics:\\n\"The Inverse Eigenvalue Problem of a Graph\"\\nLecture details here: https://t.co/uskOJS0BKD\\n@pimsmath @UVicScience https://t.co/dO4JjH45QE',\n",
       " 'Congratulations! Robert Langlands, who developed one of the most original insights of 20th-century #mathematics, was named the winner of the 2018 @abel_prize at a ceremony in Norway this morning. https://t.co/ddwAk3kJPj https://t.co/2rV4Z5zy1p',\n",
       " 'PIMS lecture: Troy Day: tomorrow at 4 p.m. in Robert Schultz Theatre #StatsUmanSeminar https://t.co/8lX0rPjgd6',\n",
       " 'Learn where Mathematics meets Evolutionary Biology tomorrow at PIMS @umanitoba in a Distinguished Lecture with Troy Day of @queensu \\n\"The Mathematics of Social Evolution\"\\nLecture details here: https://t.co/V1d13zKOGA\\n@pimsmath @umanitobasci #MathMeetsBiology https://t.co/PyVw4iR1rp',\n",
       " 'The annual Poster Session for @UBCStatistics 450 &amp; 550 will be held in the ESB Atrium on Tuesday, March 27. Come check it out!\\nCheck out the poster details here: https://t.co/eKTtNRdSBu\\n@pimsmath @ubcmath @UBC_CS @UBC https://t.co/MP08aw0ZwU',\n",
       " 'Congrats to #UBC alumnus Robert P. Langlands, winner of the prestigious Abel Prize in mathematics for his “grand unified theory of mathematics.” #science https://t.co/fpR00MPKCh https://t.co/DqEzPRSYUl',\n",
       " 'Great to see that Robert Langlands, an undergraduate alumni from our UBC Math Department @ubcmath @UBC @the_IAS has won the highly prestigious 2018 Abel Prize! https://t.co/dQiJ5ZU8PH',\n",
       " 'In Toronto for the 1st Canadian Geometry and Topology Seminar @FieldsInstitute @pimsmath',\n",
       " 'Excellent lecture “The geometry of external eigenvalue problems”  by my UBC colleague Ailana Fraser at the 1st Canadian Geometry and Topology Seminar @FieldsInstitute @pimsmath https://t.co/YR2Dn4HRiM']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prefer retweet data, get tweet text\n",
    "text = [t.retweeted_status.full_text\n",
    "            if hasattr(t, 'retweeted_status')\n",
    "            else t.full_text\n",
    "                for t in tweets]\n",
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poster',\n",
       " 'session',\n",
       " 'showcasing',\n",
       " 'work',\n",
       " 'take',\n",
       " 'place',\n",
       " 'next',\n",
       " 'tuesday.',\n",
       " 'fyi',\n",
       " 'today']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize words\n",
    "tokens = []\n",
    "for t in text:\n",
    "    for w in t.replace('\\n', '').lower().split(' '): # remove newlines, split on spaces\n",
    "        try:\n",
    "            if (\n",
    "                not (w.startswith('http') or w.startswith('@')) # ignore if URL or mention\n",
    "                and w not in stopwords.words('english') # ignore stopwords\n",
    "                and str(w).translate(punctuation) != '' # ignore punctuation\n",
    "                and w != u''): # ignore empties\n",
    "                    tokens.append(str(w).translate(punctuation))\n",
    "        except UnicodeEncodeError: pass # ignore if not ascii\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['education',\n",
       " 'available',\n",
       " 'workshop',\n",
       " 'school',\n",
       " 'event',\n",
       " 'summer',\n",
       " 'week',\n",
       " 'mathematics',\n",
       " 'here:',\n",
       " 'seminar',\n",
       " '#ubc:',\n",
       " 'distinguished',\n",
       " '-',\n",
       " 'w/',\n",
       " 'today',\n",
       " 'lecture',\n",
       " 'new',\n",
       " '&amp;',\n",
       " 'math',\n",
       " 'pims']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get word frequency\n",
    "freq = dict((t, tokens.count(t)) for t in tokens)\n",
    "sorted(freq, key=freq.get)[-20:] # slice frequent words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
